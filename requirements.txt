#fastapi==0.111.0
fastapi==0.116.1
#uvicorn==0.29.0
uvicorn==0.35.0
llama-index==0.10.37
llama-cpp-python==0.2.66
sentence-transformers==2.7.0
faiss-cpu==1.7.4
tiktoken==0.7.0
typing-extensions>=4.5.0
transformers==4.54.1
